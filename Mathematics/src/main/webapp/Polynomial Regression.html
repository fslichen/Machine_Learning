<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Insert title here</title>
</head>
<body>
	For a polynomial regression:
	yHat_0 = w_0 * x_0,0 + ... + w_n-1 * x_0,n-1
	...
	yHat_m-1 = w_0 * x_m-1,0 + ... + w_n-1 * x_m-1,n-1
	Now, determine the RSS, which stands for the residual sum of squared.
	Let X = 
	(x_0,0 ... x_0,n-1
	 ...
	 x_m-1,0 ... x_m-1,n-1)
	Let W = 
	(w_0
	 ...
	 w_m-1)
	Let Y = 
	(y_0
	 ...
	 y_m-1)
	RSS = (y_0 - yHat_0) ^ 2 + ... + (y_m-1 - yHat_m-1) ^ 2
	= (y_0 - (w_0 * x_0,0 + ... + w_n-1 * x_0,n-1)) ^ 2 + ... + (y_m-1 - (w_0 * x_m-1,0 + ... + w_n-1 * x_m-1,n-1)) ^ 2
	Now, calculate the gradient of the RSS, let it equal to zero and get:
	0 = dRSS/dW =
	(-2 * x_0,0 * (y_0 - (w_0 * x_0,0 + ... + w_n-1 * x_0,n-1)) - ... - 2 * x_m-1,0 * (y_m-1 - (w_0 * x_m-1,0 + ... + w_n-1 * x_m-1,n-1))
	 ...
	 -2 * x_0,n-1 * (y_0 - (w_0 * x_0,0 + ... + w_n-1 * x_0,n-1)) - ... - 2 * x_m-1,n-1 * (y_m-1 - (w_0 * x_m-1,0 + ... + w_n-1 * x_m-1,n-1)))
	0 =
	(x_0,0 * (y_0 - X_0,. * W) + ... + x_m-1,0 * (y_m-1 - X_m-1,. * W)
	 ...
	 x_0,n-1 * (y_0 - X_0,. * W) + ... + x_m-1,n-1 * (y_m-1 - X_m-1,. * W)
	=
	(X_.,0^T * (Y - X * W)
	 ...
	 X_.,n-1^T * (Y - X * W))
	0 = (X_.,0^T * (Y - X * W) + ... + X_.,n-1^T * (Y - X * W)) = X^T * (Y - X * W)
	Therefore W = (X^T * X) ^ (-1) * (X^T * Y)
</body>
</html>